{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA5851 Data Science Masterclass 1\n",
    "### Assignment 3: Webcrawler and NLP System\n",
    "### Laura Vodden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    "  \n",
    "  \n",
    "  \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document 2. Twitter Scraper using Selenium\n",
    "####   \n",
    "##  Rationale\n",
    "### There is a gender imbalance in STEM careers (ref).  Such an imbalance should show up as bias in language data and this bias should therefore appear and may even amplify in any predictions made based on language data (Sun et al. 2019). \n",
    "### For this analysis, Twitter is the sole website from which data were extracted. This is because tweets provide a large number and wide range of language data relating to any conceivable topic. It is possible to scrape data from Twitter using specific search terms, allowing targeted collection of information and ensuring collected data are relevant to this investigation.\n",
    "\n",
    "### The reason for extracting web content from Twitter is that Twitter behaves as a largely uncensored (with exceptions), global-scale historical record from the perspective of everyday members of society, not just the powerful and privileged, as has been the case in the past (although, importantly, and in line with the topic of this report, Tweets written by people of colour are more likely to be flagged as offensive and removed by machine learning algorithms (Wei, 2020)). In 2020, 500 million tweets were published daily. Users from around the world post their uninhibited thoughts and feelings about all kinds of topics, and so Twitter can be treated as a repository of people’s opinions and attitudes, and therefore their personal biases, and on a grander scale, the biases of society, through time. This makes Twitter an ideal source of data for sentiment analysis and natural language processing in general (ref). Because this investigation seeks to research implicit gender bias in STEM-related topics, and because gender bias is a social issue, it is sensible to look for data where people produce a high volume of text relating to, in this case, STEM careers. \n",
    "\n",
    "### For this analysis, Twitter, data covers tweets containing hashtags relating to STEM (science/scientist, technology/technologist, engineering/engineer, and math/mathematics/mathematician), which also contain the gender pronouns (she/her/hers, he/him/his). For the purpose of this research, only these two binary genders are incorporated because…. The resulting dataframe comprised xx,xxx records of STEM-related tweets from April 14, 2021. The number of STEM tweets containing female pronouns vs male pronouns was investigated.\n",
    "####  \n",
    "####  \n",
    "## Methods\n",
    "### Webscraper\n",
    "### The data from Twitter were complicated to extract – why?. Due to the perpetual scrolling nature of the site, it was decided that the best way to scrape Tweet data would be using the Selenium package. Selenium works by automating web browser activity, replicating functions such as open, click and scroll (ref). The package requires installation of a driver to interface with a browser (Chrome was used here).\n",
    "\n",
    "### Selenium was used to open, navigate and enter a search term to scrape Tweet data while scrolling downwards, allowing new Tweets to appear. The xpath function was used to select specific data (Tweet, User, Date) from the HTML inspect navigation panel.\n",
    "\n",
    "### Tweets containing the specified search terms were extracted straight into several columns: Tweet, STEM hashtags, gender pronouns. From here, information was extracted from Tweets. Sentiment analysis was performed on each tweet to determine popular sentiment towards women in STEM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from getpass import getpass\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to scrape Twitter using Selenium\n",
    "\n",
    "def get_tweet_data(card):\n",
    "    #Extract tweet data\n",
    "    #username\n",
    "    try:\n",
    "        username = card.find_element_by_xpath('.//span').text\n",
    "    except NoSuchElementException:\n",
    "        return\n",
    "    except StaleElementReferenceException:\n",
    "        return\n",
    "    #twitter handle\n",
    "    try:\n",
    "        handle = card.find_element_by_xpath('.//span[contains(text(), \"@\")]').text\n",
    "    except NoSuchElementException:\n",
    "        return\n",
    "    except StaleElementReferenceException:\n",
    "        return\n",
    "    #tweet text\n",
    "    try:\n",
    "        comment = card.find_element_by_xpath('.//div[2]/div[2]/div[1]').text\n",
    "        responding = card.find_element_by_xpath('.//div[2]/div[2]/div[2]').text\n",
    "        text = comment+responding\n",
    "    except NoSuchElementException:\n",
    "        return\n",
    "    except StaleElementReferenceException:\n",
    "        return\n",
    "    #reply count\n",
    "    try:\n",
    "        comment = card.find_element_by_xpath('//div[@data-testid=\"reply\"]').text\n",
    "    except NoSuchElementException:\n",
    "        return\n",
    "    except StaleElementReferenceException:\n",
    "        return\n",
    "    #retweet count\n",
    "    try:\n",
    "        retweet = card.find_element_by_xpath('//div[@data-testid=\"retweet\"]').text\n",
    "    except NoSuchElementException:\n",
    "        return\n",
    "    except StaleElementReferenceException:\n",
    "        return\n",
    "    #likes\n",
    "    try:\n",
    "        like = card.find_element_by_xpath('//div[@data-testid=\"like\"]').text\n",
    "    except NoSuchElementException:\n",
    "        return\n",
    "    except StaleElementReferenceException:\n",
    "        return\n",
    "    try:\n",
    "        #post date\n",
    "        date = card.find_element_by_xpath('.//time').get_attribute('datetime')\n",
    "    except NoSuchElementException:\n",
    "        return\n",
    "    except StaleElementReferenceException:\n",
    "        return\n",
    "    \n",
    "    tweet = (username, handle, text, comment, retweet, like, date)\n",
    "    return tweet \n",
    "\n",
    "# create instance of webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.twitter.com/login')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "#navigate to twitter and login\n",
    "username = driver.find_element_by_xpath('//input[@name=\"session[username_or_email]\"]')\n",
    "username.send_keys('laura.vodden@outlook.com')\n",
    "mypassword = getpass()\n",
    "\n",
    "password = driver.find_element_by_xpath('//input[@name=\"session[password]\"]')\n",
    "password.send_keys(mypassword)\n",
    "password.send_keys(Keys.RETURN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find search input and search for term\n",
    "\n",
    "#navigte to 'explore' tab\n",
    "driver.find_element_by_xpath('//a[@data-testid=\"AppTabBar_Explore_Link\"]').click()\n",
    "\n",
    "search_input = driver.find_element_by_xpath('//input[@aria-label=\"Search query\"]')\n",
    "search_input.send_keys('(science OR technology OR engineering OR math OR mathematics OR scientist OR technologist OR engineer OR mathematician) (she OR her OR he OR him) -filter:retweets')\n",
    "search_input.send_keys(Keys.RETURN)\n",
    "\n",
    "#navigte to 'latest' tab\n",
    "driver.find_element_by_link_text('Latest').click()\n",
    "\n",
    "# get all tweets on the page\n",
    "data = []\n",
    "tweet_ids = set()\n",
    "last_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "scrolling = True\n",
    "\n",
    "while scrolling:\n",
    "    page_cards = driver.find_elements_by_xpath('//div[@data-testid=\"tweet\"]')\n",
    "    for card in page_cards[-15:]:\n",
    "        tweet = get_tweet_data(card)\n",
    "        if tweet:\n",
    "            tweet_id = ''.join(tweet)\n",
    "            if tweet_id not in tweet_ids:\n",
    "                tweet_ids.add(tweet_id)\n",
    "            data.append(tweet)\n",
    "    \n",
    "    scroll_attempt = 0\n",
    "    while True:\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        sleep(1)\n",
    "        curr_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "        if last_position == curr_position:\n",
    "            scroll_attempt += 1\n",
    "            \n",
    "            #end of scroll region\n",
    "            if scroll_attempt >= 3:\n",
    "                scrolling = False\n",
    "                break\n",
    "            else:\n",
    "                sleep(2) # attempt to scroll again\n",
    "        else:\n",
    "            last_position = curr_position\n",
    "            break\n",
    "\n",
    "#save tweet data\n",
    "with open('stem_tweets_2.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    header = ['Username', 'Handle', 'Text', 'Comments', 'Retweets', 'Likes', 'Date']\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "### Data cleaning \n",
    "### There were several necessary steps involved in preparing the Tweet data for analysis using NLP methods. First, user handles were removed using a lambda function targeting the @ symbol before user handles. After this, the remaining punctuation was removed. Stop words were removed, and Tweets were Tokenised and Lemmatised. Rows containing blanks were excluded from the dataframe. \n",
    "### Furthermore, a new column was generated with values ‘M’ or ‘F’, corresponding to male or female, depending on which pronouns were present in the original Tweet.\n",
    "### The resulting dataframe contained 25,165 rows, with four columns containing the User Handle, the text of each Tweet, the tokenised and Lemmatised Tweet and Gender data.\n",
    "### The dataframe was saved as a .csv file for later use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Text</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angi</td>\n",
       "      <td>@AngiMaryssa</td>\n",
       "      <td>Blackwell is great. As a lawyer, you have to b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-14T20:32:29.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Señor Luis (1LUV)</td>\n",
       "      <td>@thiccbb69</td>\n",
       "      <td>math dumb af, if y=mx+b then y=tf don't she lo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-14T20:32:24.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jared Halpern</td>\n",
       "      <td>@JaredEHalpern</td>\n",
       "      <td>Wow, he was a hell of an engineer --Grant Imah...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-14T20:32:23.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bob Brigham</td>\n",
       "      <td>@BobBrigham</td>\n",
       "      <td>Matt Kelley is so bad he thinks coronavirus is...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-14T20:32:10.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AlaskanTzar</td>\n",
       "      <td>@AlaskanTzar</td>\n",
       "      <td>Replying to \\n@science_bradyBut he was?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-14T20:31:58.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Username          Handle  \\\n",
       "0               Angi    @AngiMaryssa   \n",
       "1  Señor Luis (1LUV)      @thiccbb69   \n",
       "2      Jared Halpern  @JaredEHalpern   \n",
       "3        Bob Brigham     @BobBrigham   \n",
       "4        AlaskanTzar    @AlaskanTzar   \n",
       "\n",
       "                                                Text Comments Retweets Likes  \\\n",
       "0  Blackwell is great. As a lawyer, you have to b...      NaN      NaN   NaN   \n",
       "1  math dumb af, if y=mx+b then y=tf don't she lo...      NaN      NaN   NaN   \n",
       "2  Wow, he was a hell of an engineer --Grant Imah...      NaN      NaN   NaN   \n",
       "3  Matt Kelley is so bad he thinks coronavirus is...      NaN      NaN   NaN   \n",
       "4            Replying to \\n@science_bradyBut he was?      NaN      NaN   NaN   \n",
       "\n",
       "                       Date  \n",
       "0  2021-04-14T20:32:29.000Z  \n",
       "1  2021-04-14T20:32:24.000Z  \n",
       "2  2021-04-14T20:32:23.000Z  \n",
       "3  2021-04-14T20:32:10.000Z  \n",
       "4  2021-04-14T20:31:58.000Z  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_csv(\"stem_tweets.csv\", dtype=object)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30284"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove handles\n",
    "tweets_df['Text'] =  tweets_df['Text'].apply(lambda x: re.sub('@[\\w]+','', str(x)))\n",
    "\n",
    "\n",
    "#Remove punctuation\n",
    "\n",
    "# remove 's, 'll, 'd  \n",
    "tweets_df['Text'] = tweets_df['Text'].str.replace(\"'s\",\"\")\n",
    "tweets_df['Text'] = tweets_df['Text'].str.replace(\"'ll\",\"\")\n",
    "tweets_df['Text'] = tweets_df['Text'].str.replace(\"'d\",\"\")\n",
    "tweets_df['Text'] = tweets_df['Text'].str.replace(\"Replying to \",\"\")\n",
    "tweets_df['Text'] = tweets_df['Text'].str.replace(\"\\n\",\"\")\n",
    " \n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    no_punct=[words for words in text if words not in string.punctuation]\n",
    "    words_wo_punct=''.join(no_punct)\n",
    "    return words_wo_punct\n",
    "\n",
    "tweets_df['Text']=tweets_df['Text'].apply(lambda x: remove_punctuation(x))\n",
    "\n",
    "\n",
    "\n",
    "# Tokenizing \n",
    "def tokenize(text):\n",
    "    split=re.split(\"\\W+\",text) \n",
    "    return split\n",
    "tweets_df['Text_Token']=tweets_df['Text'].apply(lambda x: tokenize(x.lower()))\n",
    "\n",
    "\n",
    "# Assign a gender to each tweet based on pronouns present\n",
    "tweets_df.loc[tweets_df['Text'].str.contains(' he '), 'Gender'] = 'M'\n",
    "tweets_df.loc[tweets_df['Text'].str.contains('He '), 'Gender'] = 'M'\n",
    "tweets_df.loc[tweets_df['Text'].str.contains(' him '), 'Gender'] = 'M'\n",
    "tweets_df.loc[tweets_df['Text'].str.contains(' she '), 'Gender'] = 'F'\n",
    "tweets_df.loc[tweets_df['Text'].str.contains('She'), 'Gender'] = 'F'\n",
    "tweets_df.loc[tweets_df['Text'].str.contains(' her '), 'Gender'] = 'F'\n",
    "\n",
    "# Assign a topic to each tweet based on topic in text\n",
    "tweets_df.loc[tweets_df['Text'].str.contains('science'), 'Topic'] = 'science'\n",
    "tweets_df.loc[tweets_df['Text'].str.contains('scientist'), 'Topic'] = 'science'\n",
    "tweets_df.loc[tweets_df['Text'].str.contains('technology '), 'Topic'] = 'technology'\n",
    "tweets_df.loc[tweets_df['Text'].str.contains('technogist'), 'Topic'] = 'technology'\n",
    "tweets_df.loc[tweets_df['Text'].str.contains('engineering'), 'Topic'] = 'engineering'\n",
    "tweets_df.loc[tweets_df['Text'].str.contains('engineer'), 'Topic'] = 'engineering'\n",
    "tweets_df.loc[tweets_df['Text'].str.contains('math'), 'Topic'] = 'mathematics'\n",
    "tweets_df.loc[tweets_df['Text'].str.contains('mathematics'), 'Topic'] = 'mathematics'\n",
    "tweets_df.loc[tweets_df['Text'].str.contains('mathematician'), 'Topic'] = 'mathematics'\n",
    "\n",
    "# Remove stop words\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    text=[word for word in text if word not in stopword]\n",
    "    return text\n",
    "tweets_df['Text_Token'] = tweets_df['Text_Token'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "# Lemmatizing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "tweets_df['Text_Token'] = tweets_df['Text_Token'].apply(lemmatize_text)\n",
    "#tweets_df['Text_Token'] = tweets_df['Text_Token'].str.replace(\"'',\",\"\")\n",
    "\n",
    "\n",
    "tweets_df = tweets_df[[\"Handle\", \"Text\", \"Text_Token\", \"Gender\", \"Topic\"]]\n",
    "\n",
    "\n",
    "# Drop any rows containing blanks\n",
    "tweets_df = tweets_df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "tweets_df = tweets_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Handle</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Token</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AngiMaryssa</td>\n",
       "      <td>Blackwell is great As a lawyer you have to bec...</td>\n",
       "      <td>[blackwell, great, lawyer, become, expert, com...</td>\n",
       "      <td>M</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@thiccbb69</td>\n",
       "      <td>math dumb af if ymxb then ytf dont she love me</td>\n",
       "      <td>[math, dumb, af, ymxb, ytf, dont, love]</td>\n",
       "      <td>F</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@JaredEHalpern</td>\n",
       "      <td>Wow he was a hell of an engineer Grant Imahara...</td>\n",
       "      <td>[wow, hell, engineer, grant, imahara, talk, ro...</td>\n",
       "      <td>M</td>\n",
       "      <td>engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@BobBrigham</td>\n",
       "      <td>Matt Kelley is so bad he thinks coronavirus is...</td>\n",
       "      <td>[matt, kelley, bad, think, coronavirus, noctur...</td>\n",
       "      <td>M</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@vomit_bestie</td>\n",
       "      <td>that math test i just took was my absolute bit...</td>\n",
       "      <td>[math, test, took, absolute, bitch, put, smack...</td>\n",
       "      <td>F</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Handle                                               Text  \\\n",
       "0    @AngiMaryssa  Blackwell is great As a lawyer you have to bec...   \n",
       "1      @thiccbb69     math dumb af if ymxb then ytf dont she love me   \n",
       "2  @JaredEHalpern  Wow he was a hell of an engineer Grant Imahara...   \n",
       "3     @BobBrigham  Matt Kelley is so bad he thinks coronavirus is...   \n",
       "5   @vomit_bestie  that math test i just took was my absolute bit...   \n",
       "\n",
       "                                          Text_Token Gender        Topic  \n",
       "0  [blackwell, great, lawyer, become, expert, com...      M      science  \n",
       "1            [math, dumb, af, ymxb, ytf, dont, love]      F  mathematics  \n",
       "2  [wow, hell, engineer, grant, imahara, talk, ro...      M  engineering  \n",
       "3  [matt, kelley, bad, think, coronavirus, noctur...      M      science  \n",
       "5  [math, test, took, absolute, bitch, put, smack...      F  mathematics  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17305"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "tweets_df.to_csv ('tweets_df.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "### A preliminary exploration of the data shows that the dataset is very unbalanced in terms of gender representation. 66% of the STEM Tweets are about men, and 34% are about women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of STEM Tweets by gender\n",
      "M    0.665126\n",
      "F    0.334874\n",
      "Name: Gender, dtype: float64\n",
      "\n",
      "Count of STEM Tweets by gender\n",
      "M    11510\n",
      "F     5795\n",
      "Name: Gender, dtype: int64\n",
      "\n",
      "Total Tweets: 17305\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count tweets about women vs men\n",
    "print(\"Percentage of STEM Tweets by gender\")\n",
    "counts = tweets_df['Gender'].value_counts(normalize=True)\n",
    "print(counts)\n",
    "print()\n",
    "print(\"Count of STEM Tweets by gender\")\n",
    "counts = tweets_df['Gender'].value_counts()\n",
    "print(counts)\n",
    "print()\n",
    "print(\"Total Tweets:\", len(tweets_df))\n",
    "tweets_df.Gender.value_counts().plot(kind = 'bar')\n",
    "plt.title('STEM Tweet Counts by Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender prediction using unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\"tweets_df.csv\", dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Handle</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Token</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AngiMaryssa</td>\n",
       "      <td>Blackwell is great As a lawyer you have to bec...</td>\n",
       "      <td>['blackwell', 'great', 'lawyer', 'become', 'ex...</td>\n",
       "      <td>M</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@thiccbb69</td>\n",
       "      <td>math dumb af if ymxb then ytf dont she love me</td>\n",
       "      <td>['math', 'dumb', 'af', 'ymxb', 'ytf', 'dont', ...</td>\n",
       "      <td>F</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@JaredEHalpern</td>\n",
       "      <td>Wow he was a hell of an engineer Grant Imahara...</td>\n",
       "      <td>['wow', 'hell', 'engineer', 'grant', 'imahara'...</td>\n",
       "      <td>M</td>\n",
       "      <td>engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@BobBrigham</td>\n",
       "      <td>Matt Kelley is so bad he thinks coronavirus is...</td>\n",
       "      <td>['matt', 'kelley', 'bad', 'think', 'coronaviru...</td>\n",
       "      <td>M</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@vomit_bestie</td>\n",
       "      <td>that math test i just took was my absolute bit...</td>\n",
       "      <td>['math', 'test', 'took', 'absolute', 'bitch', ...</td>\n",
       "      <td>F</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Handle                                               Text  \\\n",
       "0    @AngiMaryssa  Blackwell is great As a lawyer you have to bec...   \n",
       "1      @thiccbb69     math dumb af if ymxb then ytf dont she love me   \n",
       "2  @JaredEHalpern  Wow he was a hell of an engineer Grant Imahara...   \n",
       "3     @BobBrigham  Matt Kelley is so bad he thinks coronavirus is...   \n",
       "4   @vomit_bestie  that math test i just took was my absolute bit...   \n",
       "\n",
       "                                          Text_Token Gender        Topic  \n",
       "0  ['blackwell', 'great', 'lawyer', 'become', 'ex...      M      science  \n",
       "1  ['math', 'dumb', 'af', 'ymxb', 'ytf', 'dont', ...      F  mathematics  \n",
       "2  ['wow', 'hell', 'engineer', 'grant', 'imahara'...      M  engineering  \n",
       "3  ['matt', 'kelley', 'bad', 'think', 'coronaviru...      M      science  \n",
       "4  ['math', 'test', 'took', 'absolute', 'bitch', ...      F  mathematics  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Website/data copyright considerations\n",
    "### Even though Tweets are protected under copyright, this is an academic exercise and, as such, scraping Tweet data from Twitter does not violate copyright laws.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
