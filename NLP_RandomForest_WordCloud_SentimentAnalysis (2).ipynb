{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from getpass import getpass\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import csv\n",
    "\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.common import exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get webdriver, and then get username, password and search term as input to use in scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create webdriver instance\n",
    "def create_webdriver_instance():\n",
    "    driver = webdriver.Chrome()\n",
    "    return driver\n",
    "\n",
    "\n",
    "# Get username as input\n",
    "def get_username():\n",
    "    print(\"Enter your username or email and press ENTER:\")\n",
    "    myusername = input()\n",
    "    return myusername\n",
    " \n",
    "    \n",
    "# Get password as input    \n",
    "def get_password():\n",
    "    print(\"Enter your password and press ENTER:\")\n",
    "    mypassword = getpass()\n",
    "    return mypassword\n",
    "\n",
    "\n",
    "# Get search term as input\n",
    "def get_search_term():\n",
    "    print(\"Enter your desired search term and press ENTER:\")\n",
    "    mysearchterm = input()\n",
    "    return mysearchterm\n",
    "\n",
    "# Name output file\n",
    "def get_filename():\n",
    "    print(\"Enter your desired filename and press ENTER:\")\n",
    "    myfilename = input()\n",
    "    return myfilename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These functions log in to twitter and enter the search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log in to Twitter using username and password via specified webdriver\n",
    "def login_to_twitter(myusername, mypassword, driver):\n",
    "    url = 'https://www.twitter.com/login'\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        xpath_username = '//input[@name=\"session[username_or_email]\"]'\n",
    "        WebDriverWait(driver, 10).until(expected_conditions.presence_of_element_located((By.XPATH, xpath_username)))\n",
    "        uid_input = driver.find_element_by_xpath(xpath_username)\n",
    "        uid_input.send_keys(myusername)\n",
    "    except exceptions.TimeoutException:\n",
    "        print(\"Timeout while waiting for Login screen\")\n",
    "        return False\n",
    "\n",
    "    pwd_input = driver.find_element_by_xpath('//input[@name=\"session[password]\"]')\n",
    "    pwd_input.send_keys(mypassword)\n",
    "    try:\n",
    "        pwd_input.send_keys(Keys.RETURN)\n",
    "        url = \"https://www.twitter.com/home\"\n",
    "        WebDriverWait(driver, 10).until(expected_conditions.url_to_be(url))\n",
    "    except exceptions.TimeoutException:\n",
    "        print(\"Timeout while waiting for home screen\")\n",
    "    return True\n",
    "\n",
    "\n",
    "# Function to enter search term\n",
    "def enter_search_term(mysearchterm, driver):\n",
    "    mysearch = mysearchterm\n",
    "    driver.find_element_by_xpath('//a[@data-testid=\"AppTabBar_Explore_Link\"]').click()\n",
    "    search_input = driver.find_element_by_xpath('//input[@aria-label=\"Search query\"]')\n",
    "    search_input.send_keys(mysearch)\n",
    "    search_input.send_keys(Keys.RETURN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following functions collect the data from Tweets and save them to a csv as they are collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tweet_id(tweet):\n",
    "    return ''.join(tweet)\n",
    "\n",
    "\n",
    "def scroll_down_page(driver, last_position, num_seconds_to_load=0.5, scroll_attempt=0, max_attempts=5):\n",
    "    end_of_scroll_region = False\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    sleep(num_seconds_to_load)\n",
    "    curr_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "    if curr_position == last_position:\n",
    "        if scroll_attempt < max_attempts:\n",
    "            end_of_scroll_region = True\n",
    "        else:\n",
    "            scroll_down_page(last_position, curr_position, scroll_attempt + 1)\n",
    "    last_position = curr_position\n",
    "    return last_position, end_of_scroll_region\n",
    "\n",
    "\n",
    "def save_tweet_data_to_csv(records, filepath, mode='a+'):\n",
    "    header = ['User', 'Handle', 'PostDate', 'TweetText', 'ReplyCount', 'RetweetCount', 'LikeCount']\n",
    "    with open(filepath, mode=mode, newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if mode == 'w':\n",
    "            writer.writerow(header)\n",
    "        if records:\n",
    "            writer.writerow(records)\n",
    "\n",
    "\n",
    "def collect_all_tweets_from_current_view(driver, lookback_limit=25):\n",
    "    page_cards = driver.find_elements_by_xpath('//div[@data-testid=\"tweet\"]')\n",
    "    if len(page_cards) <= lookback_limit:\n",
    "        return page_cards\n",
    "    else:\n",
    "        return page_cards[-lookback_limit:]\n",
    "\n",
    "\n",
    "def extract_data_from_current_tweet_card(card):\n",
    "    try:\n",
    "        user = card.find_element_by_xpath('.//span').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        user = \"\"\n",
    "    except exceptions.StaleElementReferenceException:\n",
    "        return\n",
    "    try:\n",
    "        handle = card.find_element_by_xpath('.//span[contains(text(), \"@\")]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        handle = \"\"\n",
    "    try:\n",
    "        postdate = card.find_element_by_xpath('.//time').get_attribute('datetime')\n",
    "    except exceptions.NoSuchElementException:\n",
    "        return\n",
    "    try:\n",
    "        _comment = card.find_element_by_xpath('.//div[2]/div[2]/div[1]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        _comment = \"\"\n",
    "    try:\n",
    "        _responding = card.find_element_by_xpath('.//div[2]/div[2]/div[2]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        _responding = \"\"\n",
    "    tweet_text = _comment + _responding\n",
    "    try:\n",
    "        reply_count = card.find_element_by_xpath('.//div[@data-testid=\"reply\"]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        reply_count = \"\"\n",
    "    try:\n",
    "        retweet_count = card.find_element_by_xpath('.//div[@data-testid=\"retweet\"]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        retweet_count = \"\"\n",
    "    try:\n",
    "        like_count = card.find_element_by_xpath('.//div[@data-testid=\"like\"]').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        like_count = \"\"\n",
    "\n",
    "    tweet = (user, handle, postdate, tweet_text, reply_count, retweet_count, like_count)\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function to call all other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(myusername, mypassword, mysearchterm, filepath, page_sort='Latest'):\n",
    "    try:\n",
    "        # create empty .csv file to save tweet data to\n",
    "        save_tweet_data_to_csv(None, filepath, 'w')  \n",
    "        last_position = None\n",
    "        end_of_scroll_region = False\n",
    "        unique_tweets = set()\n",
    "\n",
    "        # create new webdriver instance\n",
    "        driver = create_webdriver_instance()\n",
    "        logged_in = login_to_twitter(myusername, mypassword, driver)\n",
    "        if not logged_in:\n",
    "            return\n",
    "\n",
    "        # enter search term on explore page\n",
    "        enter_search_term(mysearchterm, driver)\n",
    "\n",
    "        #collect Tweets and scroll infinitely, save Tweets as they are collected\n",
    "        while not end_of_scroll_region:\n",
    "            cards = collect_all_tweets_from_current_view(driver)\n",
    "            for card in cards:\n",
    "                try:\n",
    "                    tweet = extract_data_from_current_tweet_card(card)\n",
    "                except exceptions.StaleElementReferenceException:\n",
    "                    continue\n",
    "                if not tweet:\n",
    "                    continue\n",
    "                tweet_id = generate_tweet_id(tweet)\n",
    "                if tweet_id not in unique_tweets:\n",
    "                    unique_tweets.add(tweet_id)\n",
    "                    save_tweet_data_to_csv(tweet, filepath)\n",
    "            last_position, end_of_scroll_region = scroll_down_page(driver, last_position)\n",
    "        driver.quiralt()\n",
    "    except:\n",
    "        print(\"Scrape terminated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your username or email and press ENTER:\n",
      "0478632991\n",
      "Enter your password and press ENTER:\n",
      "········\n",
      "Enter your desired filename and press ENTER:\n",
      "harleydavidson.csv\n",
      "Enter your desired search term and press ENTER:\n",
      "harley davidson australia\n",
      "Timeout while waiting for home screen\n",
      "Scrape terminated\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    myusername = get_username()\n",
    "    mypassword = get_password()\n",
    "    filepath = get_filename()\n",
    "    mysearchterm = get_search_term()\n",
    "\n",
    "    \n",
    "main(myusername, mypassword, mysearchterm, filepath, page_sort='Latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
